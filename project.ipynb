{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FINAL PROJECT: STUDENT PERFORMANCE FACTORS <center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. INFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Member Information\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "|No. | Name          | Student ID   | Email                    |\n",
    "|:--:|:-------------:|:------------:|:------------------------:|\n",
    "| 1  | Vo Hung Khoa  | 22127202     | vhkhoa22@clc.fitus.edu.vn|\n",
    "| 2  | Vu Tuan Hung  | 22127137     | vthung22@clc.fitus.edu.vn|\n",
    "| 3  | HUynh Tan Dat| 22127059     | htdat222@clc.fitus.edu.vn|\n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Project Information \n",
    "### 1. Project Introduction \n",
    "- In this project, students are required to select a public dataset, such as those available on *Kaggle*, related to a topic of interest to their group. The project involves exploring the dataset, which often includes preprocessing steps, and identifying meaningful questions that can be answered using the data. Students are then tasked with preprocessing and analyzing the data to address each question effectively, demonstrating their ability to draw insights and conclusions from the analysis.\n",
    "\n",
    "### 2. Topic\n",
    "- The chosen topic: **Student Performance Factors** \n",
    "\n",
    "- Using a dataset that covers study habits, attendance, parental involvement, and other factors, the project aims to analyze how these aspects impact students' exam performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Project Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Library and Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Library \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math \n",
    "%matplotlib inline\n",
    "\n",
    "# Import more library if you need it\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ydata_profiling import ProfileReport\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries for data manipulation, visualization, and mathematical computations. These libraries provide essential functions for handling datasets and analyzing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv(\"./StudentPerformanceFactors.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is loaded from a `CSV` file using `Pandas`. This allows us to work with the data as a `DataFrame`, making it easier to manipulate and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Hanlde Null and Duplicate Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1.1. Data Overview*\n",
    "\n",
    "To get a big-picture view of the data, we can use the `info()` function to display dataset information, including the **column names**, **data types**, **non-null counts**, and memory usage. This helps us identify any potential issues, such as **missing values** or **incorrect data types**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: There are some null values in the dataset, so we are going to drop them all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1.2. Handle Missing Value*\n",
    "Missing values can introduce bias or errors in analysis. Rows with missing values are dropped to ensure the dataset is complete.\n",
    "\n",
    "**Potential Issues Caused by Missing Values:**\n",
    "- **Bias:** Missing data can lead to biased results if the absence of values is not random.\n",
    "- **Reduced Sample Size:** Retaining rows with missing values reduces the effective size of the dataset, limiting the statistical power of analysis.\n",
    "- **Errors in Machine Learning Models:** Models may fail to train or make incorrect predictions due to incomplete data.\n",
    "\n",
    "**Conclusion:** Dropping rows with missing values ensures the dataset is reliable and suitable for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null-value\n",
    "data.dropna(axis = 0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** There are **no null values** in the `dataset`, which indicates that we can confidently proceed to the next step in the preprocessing pipeline without concerns about incomplete data impacting our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1.3. Remove duplicate rows*\n",
    "Duplicate rows can distort analysis by giving undue weight to repeated data points. Duplicates are identified and removed to maintain data integrity.\n",
    "\n",
    "**Why Remove Duplicates?**\n",
    "- **Data Integrity:** Duplicate rows can skew the statistical distribution of data.\n",
    "- **Accuracy in Machine Learning Models:** Repeated data points may cause models to overfit or misinterpret trends.\n",
    "- **Efficiency:** Removing duplicates reduces computational overhead, especially in large datasets.\n",
    "\n",
    "**Example:** If the same student's performance data is recorded multiple times, their scores may have undue influence on statistical summaries or model predictions.\n",
    "\n",
    "To maintain the `accuracy` and `reliability` of the dataset, duplicates are **identified** and **removed.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Handle Categorical Columns and Ouliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.1. Overview* \n",
    "\n",
    "To completing the data preprocessing, we need to handle the object values and convert them to numeric values. Firstly, we need to learn more about the dataset we are going to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Attribute                | Description                                                                 |\n",
    "|--------------------------|-----------------------------------------------------------------------------|\n",
    "| Hours_Studied            | Number of hours spent studying per week.                                    |\n",
    "| Attendance               | Percentage of classes attended.                                             |\n",
    "| Parental_Involvement     | Level of parental involvement in the student's education (Low, Medium, High).|\n",
    "| Access_to_Resources      | Availability of educational resources (Low, Medium, High).                 |\n",
    "| Extracurricular_Activities| Participation in extracurricular activities (Yes, No).                      |\n",
    "| Sleep_Hours              | Average number of hours of sleep per night.                                 |\n",
    "| Previous_Scores          | Scores from previous exams.                                                 |\n",
    "| Motivation_Level         | Student's level of motivation (Low, Medium, High).                          |\n",
    "| Internet_Access          | Availability of internet access (Yes, No).                                  |\n",
    "| Tutoring_Sessions        | Number of tutoring sessions attended per month.                             |\n",
    "| Family_Income            | Family income level (Low, Medium, High).                                   |\n",
    "| Teacher_Quality          | Quality of the teachers (Low, Medium, High).                               |\n",
    "| School_Type              | Type of school attended (Public, Private).                                  |\n",
    "| Peer_Influence           | Influence of peers on academic performance (Positive, Neutral, Negative).   |\n",
    "| Physical_Activity        | Average number of hours of physical activity per week.                      |\n",
    "| Learning_Disabilities    | Presence of learning disabilities (Yes, No).                               |\n",
    "| Parental_Education_Level | Highest education level of parents (High School, College, Postgraduate).   |\n",
    "| Distance_from_Home       | Distance from home to school (Near, Moderate, Far).                         |\n",
    "| Gender                   | Gender of the student (Male, Female).                                       |\n",
    "| Exam_Score               | Final exam score.                                                           |\n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.2. Convert categorical data type to numeric data type* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why:** Numerical data allows statistical and machine learning algorithms to process the information effectively.\n",
    "\n",
    "**Mappings used:**\n",
    "- `Low`/`Medium`/`High` -> 0/1/2 (Ordinal mapping for levels)\n",
    "- `High School`/`College`/`Postgraduate` -> 0/1/2 (Ordinal mapping for education levels)\n",
    "- `Near`/`Moderate`/`Far` -> 0/1/2 (Ordinal mapping for distances)\n",
    "- `Positive`/`Neutral`/`Negative` -> 2/1/0 (Ordinal mapping for sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Define ordinal mappings for specific columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ordinal mappings for specific columns.\n",
    "\n",
    "ordinal_mapping = {\"Low\": 0, \"Medium\": 1, \"High\": 2}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if set(data[column].unique()).issubset(ordinal_mapping.keys()):  \n",
    "        data[column] = data[column].map(ordinal_mapping)\n",
    "\n",
    "education_mapping = {\"High School\": 0, \"College\": 1, \"Postgraduate\": 2}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if set(data[column].unique()).issubset(education_mapping.keys()):  \n",
    "        data[column] = data[column].map(education_mapping)\n",
    "\n",
    "distance_mapping = {\"Near\": 0, \"Moderate\": 1, \"Far\": 2}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if set(data[column].unique()).issubset(distance_mapping.keys()):  \n",
    "        data[column] = data[column].map(distance_mapping)\n",
    "\n",
    "sentiment_mapping = {\"Positive\": 2, \"Neutral\": 1, \"Negative\": 0}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if set(data[column].unique()).issubset(sentiment_mapping.keys()): \n",
    "        data[column] = data[column].map(sentiment_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Handle remaining categorical columns with arbitrary unique values by encoding them as integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle remaining categorical columns\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    unique_values = data[column].unique()\n",
    "    mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "    data[column] = data[column].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures all categorical columns are numeric, even if they don’t follow an ordinal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** All columns are now correctly typed, ensuring compatibility for further processing and analysis. We are ready to proceed to the next steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Handle Outliers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *3.1. Check Ouliers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate a dataset, we can use the `describe()` function. This function is widely used to provide a summary of **key statistical** measures for the dataset, helping to quickly assess its quality and characteristics:\n",
    "\n",
    "- `count`: The number of non-null values in the dataset.\n",
    "- `mean`: The average of the values in the dataset.\n",
    "- `std`: The standard deviation, which measures the spread of the data.\n",
    "- `min`: The smallest value in the dataset.\n",
    "- `25%`, `50%`, `75%`: The 25th, 50th (median), and 75th percentiles, which help to understand the distribution of the data.\n",
    "- `max`: The largest value in the dataset.\n",
    "\n",
    "These statistics help identify potential issues such as missing values, outliers, or skewed distributions, allowing for better data validation and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** In the `Exam_score` column, there is a value of **101**, which is outside the valid range `(0-100)`. To ensure data validity and consistency, it is necessary to remove or handle these invalid values by dropping them from the dataset. This process helps maintain the integrity of the data before further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *3.2. Handlle scores*\n",
    "\n",
    "Outliers in exam scores or previous scores can skew analysis. Scores outside this range are unrealistic and likely indicate data errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with scores outside the valid range (0-100) are removed.\n",
    "\n",
    "data = data[(data[\"Exam_Score\"] <= 100) & (data[\"Exam_Score\"] >= 0)]\n",
    "data = data[(data[\"Previous_Scores\"] <= 100) & (data[\"Previous_Scores\"] >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check to ensure everything is ready for the next step.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns are in well format so now we can move on the next step!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *3.3. Save Cleaned Dataset*\n",
    "\n",
    "Save the cleaned and preprocessed dataset to a new `CSV` file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and preprocessed dataset to a new CSV file for future use.\n",
    "data.to_csv(\"./StudentPerformanceFactors_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Exploratory Data Analysis - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Overall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libs\n",
    "# !pip install numba==0.53.1\n",
    "# !pip install ydata-profiling\n",
    "# !pip install visions --upgrade\n",
    "# !pip install ydata-profiling --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./StudentPerformanceFactors_Cleaned.csv')\n",
    "profile = ProfileReport(data)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Additional Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain deeper insights into the factors affecting student performance, we will create additional visualizations. These visualizations will help us understand the relationships between various factors and the final exam scores.\n",
    "\n",
    "#### *2.1. Distribution of Exam Scores*\n",
    "\n",
    "First, let's visualize the distribution of exam scores to understand the overall performance of students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of Exam Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Exam_Score'], bins=20, kde=True)\n",
    "plt.title('Distribution of Exam Scores', fontsize=16)\n",
    "plt.xlabel('Exam Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.2. Visualizing the Distribution of Categorical Attributes*\n",
    "\n",
    "To further understand the dataset, we visualize the distribution of various categorical attributes. This helps us identify any imbalances or patterns in the data that could influence our analysis. The following plot shows the distribution of each categorical attribute in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all categorical attributes\n",
    "categorical_columns = ['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 'Motivation_Level',\n",
    "                         'Internet_Access', 'Family_Income', 'Teacher_Quality', 'School_Type', 'Peer_Influence',\n",
    "                         'Learning_Disabilities', 'Parental_Education_Level', 'Distance_from_Home', 'Gender']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(data=data, x=column, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.3. Correlation Table and Visualization*\n",
    "\n",
    "To better understand the relationships between different variables in our dataset, we will create a correlation table and visualize it using a heatmap. This will help us identify which factors are most strongly associated with exam scores and other key attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the correlations variable is defined\n",
    "correlations = data.corr()\n",
    "\n",
    "# Display the correlation coefficients as a DataFrame\n",
    "correlation_df = correlations.reset_index()\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.select_dtypes(include=['category']).columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.4. Exploring the Relationship Between Exam Scores and Key Factors*\n",
    "\n",
    "To gain deeper insights into how certain factors impact exam performance, we use box plots to analyze the relationship between Exam_Score and two crucial predictors:\n",
    "\n",
    "- `Hours Studied`: This helps identify the variability of exam scores across different levels of study time.\n",
    "- `Attendance`: This explores whether attending more classes correlates with better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "\n",
    "# Box Plot cho yếu tố 'Hours_Studied'\n",
    "sns.boxplot(data=data, x='Hours_Studied', y='Exam_Score', ax=axes[0])\n",
    "axes[0].set_title('Box Plot of Exam Scores by Hours Studied', fontsize=16)\n",
    "axes[0].set_xlabel('Hours Studied', fontsize=14)\n",
    "axes[0].set_ylabel('Exam Score', fontsize=14)\n",
    "\n",
    "# Box Plot cho yếu tố 'Attendance'\n",
    "sns.boxplot(data=data, x='Attendance', y='Exam_Score', ax=axes[1])\n",
    "axes[1].set_title('Box Plot of Exam Scores by Attendance', fontsize=16)\n",
    "axes[1].set_xlabel('Attendance', fontsize=14)\n",
    "axes[1].set_ylabel('Exam Score', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing these two factors side-by-side, we can identify potential trends and relationships that might inform further analysis or predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.5. Pair Plot Analysis of Continuous Variables*\n",
    "\n",
    "To better understand the relationships and interactions among continuous variables, a pair plot is generated for the following features: `Hours_Studied`, `Attendance`, `Previous_Scores`, `Exam_Score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "sns.pairplot(data[['Hours_Studied', 'Attendance', 'Previous_Scores', 'Exam_Score']])\n",
    "plt.suptitle('Pair Plot of Continuous Variables', fontsize=8)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization gives a holistic view of the continuous variables, allowing us to spot trends such as whether higher attendance or prior scores consistently lead to better exam outcomes. It serves as a foundation for determining which variables to prioritize in further modeling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Ask Meaningful Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1: Which factors (e.g., Hours_Studied, Motivation_Level) have the strongest correlation with Exam_Score?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Why Answer This Question?**\n",
    "- **Identifying Key Influences**: This question helps determine which factors have the strongest impact on exam performance, guiding targeted interventions to improve student outcomes.\n",
    "- **Resource Prioritization**: Understanding these relationships is practical for prioritizing resources and focusing efforts on the most impactful variables.\n",
    "\n",
    "#### **What Will Be Gained?**\n",
    "- A ranked list of factors based on their correlation with **Exam_Score**.\n",
    "- Insights into relationships between key features like **Hours_Studied**, **Motivation_Level**, and **Exam_Score**.\n",
    "\n",
    "#### **Steps to Answer:**\n",
    "1. **Correlation Analysis**:\n",
    "   - Calculate correlation coefficients (e.g., Pearson, Spearman) between independent variables and **Exam_Score**.\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - Use regression models or feature importance techniques (e.g., Random Forest, Gradient Boosting) to determine key predictors.\n",
    "\n",
    "3. **Visualization**:\n",
    "   - Create visual representations (e.g., heatmaps, bar charts) to clearly compare the impact of each factor.\n",
    "\n",
    "#### **Answer question**\n",
    "Before we dive deeper into identifying which factors influence Exam_Score the most, we start by understanding the relationships between all variables and our target variable. To achieve this, we calculate the correlation coefficients using two methods: Pearson and Spearman. Pearson correlation helps us uncover linear relationships, while Spearman correlation is particularly useful for non-linear relationships.\n",
    "\n",
    "However, our dataset contains categorical variables (e.g., Gender, School_Type) that need to be converted into numerical format before we calculate correlations. To do this, we use Label Encoding, which assigns a numeric value to each category. Once the data is prepared, we compute both Pearson and Spearman correlations for all features in the dataset. Finally, we visualize the results using bar plots, which allow us to quickly identify which factors are most strongly correlated with exam performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset to avoid modifying the original data\n",
    "data_encoded = data.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = data_encoded.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data_encoded[col] = LabelEncoder().fit_transform(data_encoded[col])\n",
    "\n",
    "# Calculate Pearson and Spearman correlations\n",
    "correlation_pearson = data_encoded.corr(method='pearson')['Exam_Score'].sort_values(ascending=False)\n",
    "correlation_spearman = data_encoded.corr(method='spearman')['Exam_Score'].sort_values(ascending=False)\n",
    "\n",
    "# Display the top factors by correlation\n",
    "print(\"Top Pearson Correlations with Exam_Score:\")\n",
    "print(correlation_pearson)\n",
    "\n",
    "print(\"\\nTop Spearman Correlations with Exam_Score:\")\n",
    "print(correlation_spearman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the correlations calculated, we can now visualize the results to better interpret the strength of these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Pearson correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "correlation_pearson.drop('Exam_Score').plot(kind='bar')\n",
    "plt.title('Pearson Correlation with Exam_Score')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Predictors:**\n",
    "- Attendance and Hours_Studied are the strongest predictors of Exam_Score, with correlation coefficients of approximately 0.6 and 0.5, respectively. This indicates a strong positive linear relationship, where higher attendance and study hours lead to better scores.\n",
    "- Previous_Scores also shows a moderate positive correlation (~0.3), suggesting that past academic performance is a reasonable indicator of future success.\n",
    "\n",
    "**Supportive Features:**\n",
    "- Access to Resources and Parental Involvement have weaker positive correlations (~0.2), indicating that while these factors support learning, they are not as impactful as attendance or study habits.\n",
    "- Features like Motivation_Level and Tutoring_Sessions show even weaker correlations, highlighting their limited direct impact.\n",
    "\n",
    "**Negative or Insignificant Predictors:** \n",
    "- Factors such as Learning Disabilities, Internet Access, and Distance from Home show weak or negative correlations. These features either have minimal influence or might negatively affect performance in specific cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Spearman correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "correlation_spearman.drop('Exam_Score').plot(kind='bar', color='skyblue')\n",
    "plt.title('Spearman Correlation with Exam_Score')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consistency with Pearson:**\n",
    "\n",
    "- The Attendance and Hours_Studied features remain the strongest predictors, with slightly higher correlation coefficients (up to 0.7). This indicates that their relationship with Exam_Score holds even for non-linear trends.\n",
    "\n",
    "- Previous_Scores is again a strong contributor, reflecting consistency across both methods.\n",
    "\n",
    "**Enhanced Perspective:**\n",
    "\n",
    "- Access to Resources and Parental Involvement maintain their moderate rankings, but Spearman correlation slightly amplifies the importance of features with non-linear impacts, such as \n",
    "Motivation_Level and Parental Education Level.\n",
    "\n",
    "- This suggests that some features, while weakly correlated linearly, may still have meaningful non-linear relationships with performance.\n",
    "\n",
    "**Weak Predictors:** Similar to Pearson, features like Distance from Home, Learning Disabilities, and Internet Access remain weak predictors, confirming their limited role in influencing exam performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the Relationship Between Important Factors and Exam_Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand how the most critical factors—Attendance, Hours_Studied, and Previous_Scores—influence academic performance, we visualize these relationships using scatter plots and box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attendance vs. Exam_Score: We create a scatter plot to examine the trend between Attendance and Exam_Score. This helps illustrate whether higher attendance correlates with improved exam performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Attendance vs Exam_Score\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=data, x='Attendance', y='Exam_Score', color='blue', alpha=0.6)\n",
    "plt.title('Effect of Attendance on Exam_Score')\n",
    "plt.xlabel('Attendance')\n",
    "plt.ylabel('Exam_Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hours_Studied vs. Exam_Score: A scatter plot is also used to visualize the impact of study hours on exam scores. This will highlight if increasing the number of study hours contributes to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Hours_Studied vs Exam_Score\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=data, x='Hours_Studied', y='Exam_Score', color='green', alpha=0.6)\n",
    "plt.title('Effect of Hours_Studied on Exam_Score')\n",
    "plt.xlabel('Hours_Studied')\n",
    "plt.ylabel('Exam_Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Previous_Scores vs. Exam_Score: To explore the effect of previous academic performance, we use a box plot. By dividing Previous_Scores into quartiles, we can observe how different ranges of past scores relate to Exam_Score distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot: Previous_Scores vs Exam_Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x=pd.qcut(data['Previous_Scores'], q=4), y='Exam_Score', palette='coolwarm')\n",
    "plt.title('Effect of Previous Scores on Exam_Score')\n",
    "plt.xlabel('Previous_Scores (Quartiles)')\n",
    "plt.ylabel('Exam_Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These visualizations provide a clear picture of how these factors interact with exam performance and further validate their importance. Below is the Python code to generate the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion**\n",
    "\n",
    "From the analysis and visualizations, it is evident that Attendance, Hours_Studied, and Previous_Scores are the most significant factors influencing academic success. These factors consistently show strong positive relationships with Exam_Score, underscoring their importance in achieving high performance.\n",
    "\n",
    "**Practical Implications**\n",
    "\n",
    "- For Students: Regular attendance and disciplined study hours should be prioritized as they have the most significant impact on exam performance. Additionally, leveraging past performance insights can help identify areas for improvement.\n",
    "\n",
    "- For Educators: Efforts should focus on encouraging attendance, fostering productive study environments, and providing targeted support to students with lower previous scores to enhance their outcomes.\n",
    "\n",
    "- For Policymakers: Ensuring equitable access to resources and creating structured interventions for underperforming students can further support academic success.\n",
    "\n",
    "In summary, while academic success is influenced by a combination of factors, consistent attendance, effective study habits, and leveraging prior performance are the strongest predictors. These insights serve as actionable guidance for students, educators, and institutions aiming to improve academic outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2: What is the minimum number of study hours required to achieve a high Exam_Score (e.g., above 80)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Why Answer This Question?**\n",
    "- This question helps determine the threshold of study hours necessary to achieve high performance, optimizing study time while ensuring success.\n",
    "- It is particularly useful for students and educators in planning efficient study schedules.\n",
    "\n",
    "#### **What Will Be Gained?**\n",
    "- A specific value or range of **Hours_Studied** required to achieve a high score.\n",
    "- A deeper understanding of the relationship between study time and performance.\n",
    "\n",
    "#### **Steps to Answer:**\n",
    "1. **Group Data**:\n",
    "   - Categorize data into groups based on score thresholds (e.g., above and below 80).\n",
    "\n",
    "2. **Analyze Relationship**:\n",
    "   - Use scatter plots to visualize the relationship between **Hours_Studied** and **Exam_Score**.\n",
    "   - Apply linear regression to determine the pattern.\n",
    "\n",
    "3. **Identify Threshold**:\n",
    "   - Use quantile analysis or logistic regression to pinpoint the minimum required study hours.\n",
    "\n",
    "#### **Answer Question**\n",
    "\n",
    "To determine the minimum number of study hours required to achieve a high **Exam_Score** (e.g., above 80), we first focus on high-performing students and their study patterns. By grouping the dataset based on a score threshold (Exam_Score > 80), we can isolate the study habits of top performers. This approach allows us to analyze how many hours are typically required to achieve such performance levels.\n",
    "\n",
    "Next, we analyze the distribution of **Hours_Studied** among high performers using a histogram. This visualization helps identify key patterns, such as the minimum and median study hours required for success. Additionally, we use scatter plots to examine the broader relationship between **Hours_Studied** and **Exam_Score** across the entire dataset. These plots highlight trends or thresholds that can guide actionable recommendations.\n",
    "\n",
    "Finally, we utilize quantile analysis to pinpoint specific thresholds for **Hours_Studied**. This provides a clear benchmark for students aiming to achieve high scores while optimizing their study time. The following analysis demonstrates these steps in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter high-performing students (Exam_Score > 80)\n",
    "high_performers = data[data['Exam_Score'] > 80]\n",
    "\n",
    "# Display the first few rows of high-performing students\n",
    "print(\"High Performers Data (Exam_Score > 80):\")\n",
    "high_performers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the high-performing students identified, we can now explore their study habits in more detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we visualize the distribution of **Hours_Studied** for students who achieved an **Exam_Score > 80**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the distribution of Hours_Studied for high-performing students\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(high_performers['Hours_Studied'], bins=10, color='orange', alpha=0.7)\n",
    "plt.title('Distribution of Hours_Studied for High Performers (Exam_Score > 80)')\n",
    "plt.xlabel('Hours_Studied')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Patterns Among High Performers:**\n",
    "- The histogram indicates that most high-performing students (**Exam_Score > 80**) study between **15 and 25 hours**. This suggests that this range is optimal for achieving high scores.\n",
    "- The highest frequency of high performers is observed at **15–20 hours**, emphasizing this as a critical threshold for students aiming for top performance.\n",
    "\n",
    "**Threshold Indicators:**\n",
    "- A small proportion of high performers study fewer than **10 hours**, indicating that minimal study time is not sufficient for most students to achieve high scores.\n",
    "- Few students exceed **30 hours**, suggesting diminishing returns beyond this point, as intensive study hours may not yield significantly better results.\n",
    "\n",
    "**Recommendations:**\n",
    "- Students aiming for high scores should target **at least 15 hours of study**, with **20 hours** being an ideal benchmark.\n",
    "- Those studying fewer than **10 hours** may need to reassess their study strategies and dedicate more time to preparation to achieve competitive scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the distribution of study hours visualized, we can now calculate specific thresholds such as the minimum, median, and 25th percentile of **Hours_Studied** for high-performing students. These thresholds will provide concrete benchmarks to guide students in planning their study time effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate thresholds for study hours among high performers\n",
    "min_hours = high_performers['Hours_Studied'].min()\n",
    "median_hours = high_performers['Hours_Studied'].median()\n",
    "quantile_25 = high_performers['Hours_Studied'].quantile(0.25)\n",
    "\n",
    "# Display calculated thresholds\n",
    "print(f\"Minimum Hours Studied for High Performers: {min_hours}\")\n",
    "print(f\"Median Hours Studied for High Performers: {median_hours}\")\n",
    "print(f\"25th Percentile Hours Studied for High Performers: {quantile_25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the thresholds for study hours among high performers calculated, we now move to examining the broader relationship between **Hours_Studied** and **Exam_Score** across the entire dataset. \n",
    "\n",
    "To achieve this, we use a scatter plot to visualize the trends and identify key patterns. The plot will include:\n",
    "- A horizontal line at **Exam_Score = 80**, representing the high score threshold.\n",
    "- A vertical line at the minimum number of study hours required to achieve a high score, as identified earlier.\n",
    "\n",
    "This visualization will help us understand how study hours correlate with exam performance for all students, beyond just the high-performing group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between Hours_Studied and Exam_Score for all students\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=data, x='Hours_Studied', y='Exam_Score', color='green', alpha=0.6)\n",
    "plt.axhline(y=80, color='red', linestyle='--', label='High Score Threshold (80)')\n",
    "plt.axvline(x=min_hours, color='blue', linestyle='--', label=f'Minimum Hours ({min_hours})')\n",
    "plt.title('Relationship Between Hours_Studied and Exam_Score', fontsize=16)\n",
    "plt.xlabel('Hours_Studied', fontsize=14)\n",
    "plt.ylabel('Exam_Score', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations from the above Plot**\n",
    "\n",
    "1. **General Trend**:\n",
    "   - The scatter plot shows a clear positive relationship between **Hours_Studied** and **Exam_Score**. As study hours increase, exam scores generally improve, indicating that dedicating more time to studying is beneficial for academic success.\n",
    "\n",
    "2. **High Performers (Exam_Score > 80)**:\n",
    "   - Most students who achieved a score greater than 80 studied at least **10 hours**, as indicated by the clustering of points above the red horizontal line and to the right of the blue vertical line.\n",
    "   - However, there are a few exceptions where students studied fewer hours (as low as 1 hour) but still managed to score above 80. These outliers may reflect other factors influencing performance, such as prior knowledge or natural aptitude.\n",
    "\n",
    "3. **Minimum Study Hours**:\n",
    "   - The blue vertical line at **1 hour** represents the calculated minimum hours studied by a high performer. While this is the extreme minimum, the majority of high performers studied significantly more, aligning with the earlier histogram insights.\n",
    "\n",
    "4. **Plateau Effect**:\n",
    "   - Beyond **30 hours** of study, the relationship between **Hours_Studied** and **Exam_Score** seems to plateau, as scores above 90 are achieved with both moderate and extensive study hours. This suggests diminishing returns for very high levels of study.\n",
    "\n",
    "5. **High Score Threshold**:\n",
    "   - The red horizontal line at **Exam_Score = 80** clearly distinguishes high-performing students. The majority of scores below this threshold are associated with fewer study hours, reinforcing the importance of consistent and adequate study time.\n",
    "\n",
    "\n",
    "- **Key Insight**: Most high-performing students studied between **10 and 30 hours**, with **20 hours** being an optimal benchmark for achieving scores above 80.\n",
    "- **Recommendation**: While some students achieve high scores with fewer hours, aiming for at least **15–20 hours** of study significantly increases the likelihood of high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion**\n",
    "\n",
    "The analysis clearly demonstrates the importance of **Hours_Studied** in achieving high exam scores. By focusing on students with **Exam_Score > 80**, we identified key thresholds for study hours:\n",
    "\n",
    "1. The **minimum hours studied** by high performers is **1 hour**, but this is an outlier, as most high performers studied significantly more.\n",
    "2. The **median study hours** for high performers is **20 hours**, indicating this as a central benchmark for achieving high scores.\n",
    "3. The **25th percentile** of study hours is **16 hours**, suggesting that studying fewer than this amount may reduce the likelihood of achieving a high score.\n",
    "\n",
    "From the scatter plot, we observe a positive correlation between **Hours_Studied** and **Exam_Score**, with most high performers studying between **10 and 30 hours**. However, there is a **plateau effect** beyond 30 hours, indicating diminishing returns for very high study durations.\n",
    "\n",
    "#### **Key Recommendations**:\n",
    "- Students aiming for high scores should target **15–20 hours** of study as an effective benchmark.\n",
    "- While fewer study hours can lead to success in rare cases, consistent and adequate study time significantly increases the likelihood of achieving scores above **80**.\n",
    "- To optimize performance, students should balance study hours with quality study techniques, as excessive study time may not always yield proportionate benefits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3: Can factors like Attendance or Hours_Studied help improve Exam_Score even for students with lower Previous_Scores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Why Answer This Question?**\n",
    "- **Support for Low Performers**: This question addresses whether students with lower Previous_Scores can still achieve high academic performance by focusing on actionable factors like Attendance and Hours_Studied. It highlights strategies for improvement for those struggling with past performance.\n",
    "- **Actionable Insights**: Identifying the impact of these factors provides clear guidance to students and educators on where to direct efforts for better outcomes.\n",
    "- **Equity Consideration**: Understanding how external factors compensate for prior performance helps in designing interventions for students with diverse academic backgrounds.\n",
    "\n",
    "#### **What Will Be Gained?**\n",
    "- **Targeted insights**: Determine if students with lower Previous_Scores can achieve significant improvements through higher attendance and study hours.\n",
    "- **Educational impact**: Insights from this analysis can inform strategies to help struggling students.\n",
    "- **Predictive modeling**: Create a model to predict Exam_Score while focusing on the interaction between these factors.\n",
    "\n",
    "#### **Steps to Answer:**\n",
    "**1. Segment the data**: Divide students into two groups based on their `Previous_Scores` (e.g., low and high performers).\n",
    "\n",
    "**2. Analyze relationships**: Investigate whether `Attendance` and `Hours_Studied` have a stronger impact on the `Exam_Score` of low-performing students.\n",
    "\n",
    "**3. Visualize interactions**: Use plots like scatter plots and trend lines, segmented by performance groups, to observe patterns.\n",
    "\n",
    "**4. Build interaction model**: Construct a regression model with interaction terms to evaluate the combined effects of Attendance, Hours_Studied, and Previous_Score.\n",
    "\n",
    "**5. Interpret results**: Assess whether the interaction terms show that effort-based factors disproportionately benefit low performers.\n",
    "\n",
    "#### **Answer question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 1: Segment the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the question, we first need to divide students into **low performers** and **high performers** based on their `Previous_Scores`. This segmentation will help us analyze whether factors like `Attendance` and `Hours_Studied` have a stronger influence on students who started with lower scores.\n",
    "\n",
    "We define the threshold for segmentation as the **median value of** `Previous_Scores`. Students with scores below or equal to the median are considered **low performers**, while those above the median are classified as **high performers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold as the median of Previous_Scores\n",
    "threshold = data['Previous_Scores'].median()\n",
    "\n",
    "# Segment the data\n",
    "low_performers = data[data['Previous_Scores'] <= threshold]\n",
    "high_performers = data[data['Previous_Scores'] > threshold]\n",
    "\n",
    "print(f\"Median of Previous_Scores: {threshold}\")\n",
    "print(f\"Number of Low Performers: {len(low_performers)}\")\n",
    "print(f\"Number of High Performers: {len(high_performers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Median of** `Previous_Scores`: 75.0\n",
    "\n",
    "    This indicates that students scoring 75 or below are categorized as low performers, while those scoring above 75 are high performers.\n",
    "\n",
    "- **Distribution**:\n",
    "    - **Low Performers**: 3257 students\n",
    "    - **High Performers**: 3120 students\n",
    "\n",
    "The two groups are nearly balanced in size, which is ideal for comparative analysis. We can now proceed to explore how `Attendance` and `Hours_Studied` influence the `Exam_Score` in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 2: Visualizing Interactions for Both Groups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the relationships between `Attendance`, `Hours_Studied`, and `Exam_Score` for **low performers** and **high performers**, we will create scatter plots with trend lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These visualizations will help us answer:\n",
    "\n",
    "- Whether higher `Attendance` improves `Exam_Score` more significantly for low performers compared to high performers.\n",
    "\n",
    "- Whether increased `Hours_Studied` has a greater effect on `Exam_Score` for students with lower prior performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(18, 12))\n",
    "\n",
    "# Low Performers\n",
    "sns.regplot(data=low_performers, x='Attendance', y='Exam_Score', ax=axes[0, 0], scatter_kws={'alpha': 0.6}, line_kws={'color': 'crimson'}, color='royalblue')\n",
    "axes[0, 0].set_title('Low Performers: Attendance vs Exam_Score', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Attendance', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Exam Score', fontsize=12)\n",
    "\n",
    "sns.regplot(data=low_performers, x='Hours_Studied', y='Exam_Score', ax=axes[0, 1], scatter_kws={'alpha': 0.6}, line_kws={'color': 'crimson'}, color='royalblue')\n",
    "axes[0, 1].set_title('Low Performers: Hours Studied vs Exam_Score', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Hours Studied', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Exam Score', fontsize=12)\n",
    "\n",
    "# High Performers\n",
    "sns.regplot(data=high_performers, x='Attendance', y='Exam_Score', ax=axes[1, 0], scatter_kws={'alpha': 0.6}, line_kws={'color': 'navy'}, color='darkorange')\n",
    "axes[1, 0].set_title('High Performers: Attendance vs Exam_Score', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Attendance', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Exam Score', fontsize=12)\n",
    "\n",
    "sns.regplot(data=high_performers, x='Hours_Studied', y='Exam_Score', ax=axes[1, 1], scatter_kws={'alpha': 0.6}, line_kws={'color': 'navy'}, color='darkorange')\n",
    "axes[1, 1].set_title('High Performers: Hours Studied vs Exam_Score', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Hours Studied', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Exam Score', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations from the Scatter Plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Attendance vs. Exam Score:**\n",
    "\n",
    "- For **low performers**: There is a positive correlation between `Attendance` and `Exam_Score`, as evidenced by the upward slope of the trend line. Higher attendance seems to improve exam performance, even for students with lower prior scores.\n",
    "- For **high performers**: The trend line is also positive, but the slope is less steep compared to low performers. This indicates that Attendance plays a less critical role in improving `Exam_Score` for high performers.\n",
    "\n",
    "**2. Hours Studied vs. Exam Score:**\n",
    "\n",
    "- For **low performers**: The relationship between `Hours_Studied` and `Exam_Score` is moderately positive. Increased study hours show a more significant improvement for students with lower prior scores.\n",
    "- For **high performers**:\n",
    "The trend is again positive but with a gentler slope, indicating that additional study hours have less impact on high performers compared to low performers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots reveal that both `Attendance` and `Hours_Studied` are more influential for low performers. This finding supports the hypothesis that these factors can help improve exam performance, especially for students who had lower prior scores.\n",
    "\n",
    "We will proceed with Step 3 to create a predictive model and further analyze the relative importance of these factors in determining `Exam_Score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 3: Build a Predictive Model for `Exam_Score` Using `Attendance`, `Hours_Studied`, and `Previous_Scores`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to create a regression model to predict `Exam_Score` based on `Attendance`, `Hours_Studied`, and `Previous_Scores`. This will allow us to evaluate how these factors interact and contribute to improving exam performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature and Target Selection**:\n",
    "  - Features: `Attendance`, `Hours_Studied`, `Previous_Scores`\n",
    "  - Target: `Exam_Score`\n",
    "\n",
    "**2. Data Splitting**: Split the data into training and testing sets (80% training, 20% testing) for robust model evaluation.\n",
    "\n",
    "**3. Model Training**: Use a Linear Regression model as a baseline to predict Exam_Score.\n",
    "\n",
    "**4. Interpretation**: Analyze regression coefficients to understand the importance of each feature.\n",
    "\n",
    "**5. Evaluation Metrics**: Evaluate the model using Mean Absolute Error (MAE), Mean Squared Error (MSE), and \n",
    "$R^2$-score to measure accuracy and explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.1: Prepare Data and Split into Training and Testing Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['Attendance', 'Hours_Studied', 'Previous_Scores']]\n",
    "y = data['Exam_Score']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of training and testing sets\n",
    "print(f\"Training Set Shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Testing Set Shape: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is sufficiently large for training and testing, which should provide robust results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.2: Train the Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display the coefficients of the trained model\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Attendance**: The coefficient is **0.195**, meaning that for every unit increase in Attendance, the `Exam_Score` increases by approximately 0.195 points, holding other factors constant.\n",
    "- **Hours_Studied**: The coefficient is **0.289**, indicating that studying one additional hour leads to an increase of about 0.289 points in `Exam_Score`, assuming other factors remain unchanged.\n",
    "- **Previous_Scores**: The coefficient is **0.045**, showing that prior performance has a smaller influence compared to `Attendance` and `Hours_Studied`.\n",
    "\n",
    "**Insight**\n",
    "\n",
    "Both `Attendance` and `Hours_Studied` have a more significant impact on `Exam_Score` compared to `Previous_Scores`, reinforcing the hypothesis that these factors can improve performance, even for students with lower prior scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.3: Evaluate the Model on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE): 1.42**\n",
    "- On average, the predicted Exam_Score deviates from the actual score by 1.42 points.\n",
    "\n",
    "**Mean Squared Error (MSE): 6.57**\n",
    "- The average squared error is 6.57, indicating some variability in predictions, but it's not excessively large.\n",
    "\n",
    "**R-squared (R²): 0.58**\n",
    "- The model explains 58% of the variability in Exam_Score. While there’s room for improvement, this indicates that the chosen features provide a reasonable explanation for exam performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Visualizing Model Predictions and Feature Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted vs Actual Values Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before visualizing, we will plot the predicted values against the actual values in the testing set. This will help us observe how well the model captures the data's patterns. Ideally, points should be aligned along the diagonal line (`y=x`), representing perfect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Scatter plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, color='blue', label='Predicted vs Actual')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal Fit (y=x)')\n",
    "plt.xlabel('Actual Exam Scores')\n",
    "plt.ylabel('Predicted Exam Scores')\n",
    "plt.title('Predicted vs Actual Exam Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot demonstrates a reasonably good alignment of the predicted values with the actual values along the ideal diagonal line (`y=x`), suggesting that the model captures \n",
    "the relationship between features and the target variable well.\n",
    "\n",
    "However, there are noticeable deviations, particularly for higher actual scores where the model under-predicts. This could indicate a limitation in the model's ability to capture more complex patterns or potential biases in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Visualization**\n",
    "\n",
    "We will create a bar plot to visualize the importance of each feature based on their coefficients. Larger coefficients indicate higher influence on the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the linear regression model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': model.coef_\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Bar plot of feature importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Coefficient'], color='skyblue')\n",
    "plt.title('Feature Importance Based on Coefficients')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart shows that **Hours_Studied** is the most significant predictor of `Exam_Score`, followed by **Attendance**. **Previous_Scores** has the least influence on predictions.\n",
    "\n",
    "This visualization confirms the hypothesis that factors like attendance and hours studied can meaningfully contribute to improving exam scores, even for students with lower previous scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis demonstrated that factors such as **Hours_Studied** and **Attendance** significantly influence exam performance, with the following key findings:\n",
    "\n",
    "##### Key Findings\n",
    "\n",
    "1. **Importance of Hours_Studied and Attendance**:  \n",
    "   - These factors consistently contributed to higher exam scores across all students, with **Hours_Studied** having the strongest impact.  \n",
    "   - Even students with lower **Previous_Scores** saw significant improvement when these factors were emphasized.\n",
    "\n",
    "2. **Model Insights**:  \n",
    "   - The linear regression model showed that nearly 58% of the variance in exam scores could be explained by these three factors.  \n",
    "   - While **Previous_Scores** was a factor, its impact was relatively minor compared to **Hours_Studied** and **Attendance**, underscoring the opportunity for improvement regardless of prior performance.\n",
    "\n",
    "##### Actionable Recommendations\n",
    "\n",
    "- **For Students**:  \n",
    "   Focusing on increasing study hours and maintaining consistent attendance can lead to substantial performance gains, especially for those with lower starting scores.  \n",
    "\n",
    "- **For Educators**:  \n",
    "   Programs that promote structured study habits and attendance could help elevate overall performance, particularly for struggling students.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "Improving **Hours_Studied** and **Attendance** is a clear and actionable strategy to enhance academic outcomes, regardless of prior performance levels. This highlights the value of discipline and effort in overcoming initial disadvantages in exam preparedness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Question 4: Does the relationship between `Attendance` and `Exam_Score` depend on the levels of `Teacher_Quality` or `Motivation_Level`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Why Answer This Question?** \n",
    "\n",
    "1. **Understand Key Relationships:**  \n",
    "   This question explores whether `Teacher_Quality` or `Motivation_Level` moderates the relationship between `Attendance` and `Exam_Score`. This helps to better understand the underlying mechanisms behind student performance.  \n",
    "\n",
    "2. **Educational Insights:**  \n",
    "   Identifying moderation effects enables educators to tailor interventions more effectively to improve both attendance and performance outcomes.  \n",
    "\n",
    "3. **Policy Implications:**  \n",
    "   By understanding how teacher quality or student motivation interacts with attendance, policymakers can design focused strategies to enhance learning environments.\n",
    "\n",
    "4. **Address Complex Interactions:**  \n",
    "   This question goes beyond simple pairwise relationships, aiming to uncover deeper, multivariate dynamics in the dataset.\n",
    "\n",
    "#### **What Will Be Gained?**  \n",
    "\n",
    "1. **Actionable Recommendations:**  \n",
    "   - If teacher quality is a significant moderator, prioritize teacher training in schools where attendance is an issue.  \n",
    "   - If motivation is a key moderator, focus on fostering intrinsic and extrinsic motivational strategies among students.  \n",
    "\n",
    "2. **Improved Educational Strategies:**  \n",
    "   Personalize interventions based on attendance and motivation levels to ensure effective resource utilization and optimal student outcomes.\n",
    "\n",
    "3. **Enhanced Predictive Models:**  \n",
    "   Incorporating moderation effects into models makes predictions more robust and provides realistic insights for stakeholders.\n",
    "\n",
    "4. **Informed Decision-Making:**  \n",
    "   Educational administrators and policymakers can make data-driven decisions to target critical areas such as teacher quality and student engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Steps to Answer This Question**  \n",
    "\n",
    "To determine whether `Teacher_Quality` and `Motivation_Level` moderate the relationship between `Attendance` and `Exam_Score`, follow these simplified steps:\n",
    "\n",
    "\n",
    "\n",
    "1. **Data Preparation**\n",
    "   - Check for and handle any missing data in the relevant variables (`Attendance`, `Exam_Score`, `Teacher_Quality`, `Motivation_Level`).  \n",
    "   - Standardize continuous variables (e.g., `Attendance`) for better interpretability in interaction terms.\n",
    "\n",
    "\n",
    "\n",
    "2. **Exploratory Analysis**\n",
    "   - Visualize the relationship between `Attendance` and `Exam_Score`, stratified by levels of `Teacher_Quality` and `Motivation_Level`. \n",
    "   - Use scatterplots with regression lines or facet grids for better clarity.  \n",
    "   - Reassess correlations between these variables to understand their direct relationships.\n",
    "\n",
    "\n",
    "\n",
    "3. **Moderation Analysis**\n",
    "   - Fit a regression model with interaction terms to test for moderation:  \n",
    "      - Exam_Score = β0 + β1 * Attendance + β2 * Moderator + β3 * (Attendance * Moderator) + ε \n",
    "\n",
    "      - **Explanation of Terms:**\n",
    "         - **β0**: Intercept, representing the baseline `Exam_Score`.\n",
    "         - **β1 * Attendance**: Main effect of `Attendance`.\n",
    "         - **β2 * Moderator**: Main effect of the moderator (e.g., `Teacher_Quality` or `Motivation_Level`).\n",
    "         - **β3 * (Attendance * Moderator)**: Interaction term, capturing how the effect of `Attendance` on `Exam_Score` changes depending on the moderator.\n",
    "         - **ε**: Error term, accounting for unexplained variance.\n",
    "      \n",
    "      - Test separately for `Teacher_Quality` and `Motivation_Level` as moderators.\n",
    "      - Check model assumptions (linearity, residual normality, and homoscedasticity) before interpreting results. \n",
    "\n",
    "\n",
    "\n",
    "4. **Evaluate Results**\n",
    "   - Examine the interaction term (`β3`) for significance:  \n",
    "      - If significant, it indicates a moderation effect.  \n",
    "   - Visualize the effect using interaction plots, showing the relationship between `Attendance` and `Exam_Score` at different moderator levels.\n",
    "\n",
    "\n",
    "\n",
    "5. **Interpret and Conclude**\n",
    "   - Summarize the findings and identify actionable insights:  \n",
    "     - For example, if `Teacher_Quality` moderates the relationship, consider interventions to improve teacher effectiveness.  \n",
    "   - If no moderation is found, explore other potential factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Data Preparation**\n",
    "*Even though the preprocessing steps have been done above, we still need to double check to make sure everything is on track.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *1.1 Check and Handle Missing Values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we gonna read data in to `dataFrame` named `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in to `dataFrame` named `data`\n",
    "data = pd.read_csv(\"./StudentPerformanceFactors_Cleaned.csv\")\n",
    "\n",
    "# Extract four columns: \"Attendance\", \"Motivation_Level\", \"Teacher_Quality\", \"Exam_Score\"\n",
    "data = data[[\"Attendance\", \"Motivation_Level\", \"Teacher_Quality\", \"Exam_Score\"]]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we move to the next step \"Check and handle missing values\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = data.isnull().sum()\n",
    "print(\"The number of missing values in each column is:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have zero null value, so we can move on to standardize continuous variables (e.g., `Attendance`) for better interpretability in interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *1.2. Standardize continous variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_std = data.copy()\n",
    "data_std[['Attendance', 'Exam_Score']] = scaler.fit_transform(data_std[['Attendance', 'Exam_Score']])\n",
    "\n",
    "print(data_std.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Exploratory Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *2.1. Visualize the relationship by Pairplot*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the relationship** between `Attendance` and `Exam_Score`, stratified by levels of `Teacher_Quality` and `Motivation_Level`. This will help us understand how the relationship between these variables changes across different categories of teacher quality and motivation level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairplot of `Attendance` and `Exam_Score`, stratified by `Motivation_Level`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán trung vị của Exam_Score và Attendance cho từng nhóm Motivation_Level\n",
    "medians = data.groupby('Motivation_Level')[['Exam_Score', 'Attendance']].median().reset_index()\n",
    "\n",
    "\n",
    "# Tạo figure và các subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))  # 1 hàng, 3 cột\n",
    "fig.suptitle('Relationship between Attendance and Exam_Score by Motivation_Level', fontsize=16)\n",
    "\n",
    "# Các mức của Motivation_Level\n",
    "motivation_levels = data['Motivation_Level'].unique()\n",
    "\n",
    "# Tạo một palette với màu sắc khác nhau cho mỗi Motivation_Level\n",
    "colors = ['viridis', 'cubehelix', 'crest']\n",
    "\n",
    "# Vẽ biểu đồ cho mỗi mức Motivation_Level\n",
    "for i, motivation in enumerate(motivation_levels):\n",
    "        ax = axes[i]  # Chọn subplot tương ứng\n",
    "        \n",
    "        # Lọc dữ liệu theo Motivation_Level\n",
    "        filtered_data = data[data['Motivation_Level'] == motivation]\n",
    "        \n",
    "        # Vẽ scatter plot cho từng nhóm\n",
    "        sns.scatterplot(data=filtered_data, x='Attendance', y='Exam_Score', ax=ax, hue='Motivation_Level', palette=colors[i])\n",
    "        \n",
    "        # Thêm tiêu đề cho từng subplot\n",
    "        ax.set_title(f'Motivation: {motivation}')\n",
    "        \n",
    "        # Thêm label cho trục\n",
    "        ax.set_xlabel('Attendance')\n",
    "        ax.set_ylabel('Exam Score')\n",
    "\n",
    "        # Vẽ dòng trung vị cho Attendance và Exam_Score\n",
    "        median_attendance = medians[medians['Motivation_Level'] == motivation]['Attendance'].values[0]\n",
    "        median_exam_score = medians[medians['Motivation_Level'] == motivation]['Exam_Score'].values[0]\n",
    "        \n",
    "        ax.axvline(x=median_attendance, color='red', linestyle='--', label=f'Median Attendance: {median_attendance}')\n",
    "        ax.axhline(y=median_exam_score, color='blue', linestyle='--', label=f'Median Exam Score: {median_exam_score}')\n",
    "        \n",
    "        # Thêm chú thích cho dòng trung vị\n",
    "        ax.legend()\n",
    "\n",
    "# Điều chỉnh khoảng cách giữa các subplot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Điều chỉnh khoảng cách với tiêu đề chính\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**:\n",
    "- Based on the **visualizations** and the **median** values, we observe that `Motivation_Level` alone does not appear to be a major determinant in improving `Attendance` and `Exam_Score`.\n",
    "\n",
    "- The median `Exam_Score` (67) and `Attendance` (80) remain consistent across all levels of `Motivation_Level` (0, 1, 2).\n",
    "\n",
    "- This suggests that `Motivation_Level` does not significantly influence the relationship between `Attendance` and `Exam_Score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairplot of `Attendance` and `Exam_Score`, stratified by `Teacher_Quality`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_2 = data.groupby('Teacher_Quality')[['Exam_Score', 'Attendance']].median().reset_index()\n",
    "\n",
    "# Tạo figure và các subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))  # 1 hàng, 3 cột\n",
    "fig.suptitle('Relationship between Attendance and Exam_Score by Teacher_Quality', fontsize=16)\n",
    "\n",
    "# Các mức của Teacher_Quality\n",
    "teacher_quality_levels = data['Teacher_Quality'].unique()\n",
    "teacher_quality_levels.sort()\n",
    "\n",
    "# Tạo một palette với màu sắc khác nhau cho mỗi Teacher_Quality\n",
    "colors = ['viridis', 'crest', 'cubehelix']\n",
    "\n",
    "# Vẽ biểu đồ cho mỗi mức Teacher_Quality \n",
    "for i, quality in enumerate(teacher_quality_levels):\n",
    "        ax = axes[i]  # Chọn subplot tương ứng\n",
    "        \n",
    "        # Lọc dữ liệu theo Teacher_Quality\n",
    "        filtered_data = data[data['Teacher_Quality'] == quality]\n",
    "        \n",
    "        # Vẽ scatter plot cho từng nhóm\n",
    "        sns.scatterplot(data=filtered_data, x='Attendance', y='Exam_Score', ax=ax, hue='Teacher_Quality', palette=colors[i])\n",
    "        \n",
    "        # Thêm tiêu đề cho từng subplot\n",
    "        ax.set_title(f'Teacher Quality: {quality}')\n",
    "        \n",
    "        # Thêm label cho trục\n",
    "        ax.set_xlabel('Attendance')\n",
    "        ax.set_ylabel('Exam Score')\n",
    "\n",
    "        # Vẽ dòng trung vị cho Attendance và Exam_Score\n",
    "        median_attendance = medians_2[medians_2['Teacher_Quality'] == quality]['Attendance'].values[0]\n",
    "        median_exam_score = medians_2[medians_2['Teacher_Quality'] == quality]['Exam_Score'].values[0]\n",
    "        \n",
    "        ax.axvline(x=median_attendance, color='red', linestyle='--', label=f'Median Attendance: {median_attendance}')\n",
    "        ax.axhline(y=median_exam_score, color='blue', linestyle='--', label=f'Median Exam Score: {median_exam_score}')\n",
    "        \n",
    "        # Thêm chú thích cho dòng trung vị\n",
    "        ax.legend()\n",
    "\n",
    "# Điều chỉnh khoảng cách giữa các subplot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Điều chỉnh khoảng cách với tiêu đề chính\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: \n",
    "- The median `Exam_Score` (67) and `Attendance` (80) are the same for `Teacher_Quality` levels 0 and 1.\n",
    "\n",
    "- At `Teacher_Quality` = 2, the median `Exam_Score` slightly increases to 68 while `Attendance` remains unchanged.\n",
    "\n",
    "- This indicates that `Teacher_Quality` may have a minimal impact on improving `Exam_Score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *2.2. Reassessing Correlations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation Matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# 2. Visualize Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Stratified Correlation Analysis\n",
    "for teacher_quality in data['Teacher_Quality'].unique():\n",
    "    subset = data[data['Teacher_Quality'] == teacher_quality]\n",
    "    corr = subset[['Attendance', 'Exam_Score']].corr().iloc[0, 1]\n",
    "    print(f\"Correlation (Attendance vs Exam_Score) for Teacher_Quality = {teacher_quality}: {corr:.2f}\")\n",
    "\n",
    "for motivation_level in data['Motivation_Level'].unique():\n",
    "    subset = data[data['Motivation_Level'] == motivation_level]\n",
    "    corr = subset[['Attendance', 'Exam_Score']].corr().iloc[0, 1]\n",
    "    print(f\"Correlation (Attendance vs Exam_Score) for Motivation_Level = {motivation_level}: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**:\n",
    "1. **Overall Correlation Consistency**:\n",
    "\n",
    "    - The correlation between `Attendance` and `Exam_Score` remains relatively consistent across all levels of `Teacher_Quality` (0.58–0.60) and `Motivation_Level` (0.58–0.59).\n",
    "    - This suggests that neither `Teacher_Quality` nor `Motivation_Level` significantly alters the strength of the relationship between `Attendance` and `Exam_Score`.\n",
    "\n",
    "2. **Strength of Correlation:**\n",
    "\n",
    "    - The correlations (0.58–0.60) indicate a moderate positive relationship between `Attendance` and `Exam_Score`.\n",
    "    - Higher attendance is moderately associated with higher exam scores, but the effect size is not particularly large.\n",
    "\n",
    "3. **Minimal Variation Across Groups:**\n",
    "\n",
    "    - The minor differences in correlation values across levels (maximum difference: 0.02) suggest that `Teacher_Quality` and `Motivation_Level` are not substantial moderators of the `Attendance`-`Exam_Score` relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Moderation Analysis** \n",
    "\n",
    "**Why use this model?**\n",
    "\n",
    "*To analyze whether the relationship between `Attendance` and `Exam_Score` changes depending on the level of another variable (the moderator) we gonna use the [Moderation (statistics) equation](https://en.wikipedia.org/wiki/Moderation_(statistics)):*\n",
    "<center> Exam_Score = β0 + β1 * Attendance + β2 * Moderator + β3 * (Attendance * Moderator) + ε <center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale for Using This Model:**\n",
    "\n",
    "1. **Exam_Score as the Dependent Variable**\n",
    "\n",
    "    - The primary interest is to understand factors influencing `Exam_Score`. This model allows us to examine how:\n",
    "        - **Direct attendance** affects `Exam_Score` (β1)\n",
    "        - The **moderator’s main** effect (β2)\n",
    "        - The interaction between `Attendance` and the moderator (β3) influences the outcome.\n",
    "\n",
    "2. **Moderation Analysis**\n",
    "\n",
    "    - Moderation analysis is vital when exploring:\n",
    "\n",
    "        - How external factors (`Teacher_Quality`, `Motivation_Level`) shape the strength or direction of a relationship.\n",
    "        - Potential customized interventions for improving outcomes based on specific groups or conditions.\n",
    "\n",
    "3. **Flexibility**\n",
    "\n",
    "    - The model is scalable for multiple moderators or covariates, allowing more comprehensive insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *3.1. Fit the Moderation Model*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. **`Teacher_Quality` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datadata\n",
    "data_std['Interaction_TQ'] = data_std['Attendance'] * data_std['Teacher_Quality']\n",
    "X = sm.add_constant(data_std[['Attendance', 'Teacher_Quality', 'Interaction_TQ']])\n",
    "y = data_std['Exam_Score']\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "1. **Analysis and Insights Related to the Research Question**\n",
    "    - **Direct Relationship Between `Attendance` and `Exam_Score`**\n",
    "\n",
    "        - The coefficient for `Attendance` (0.576, p < 0.001) indicates a strong and significant positive relationship between class attendance and exam scores.\n",
    "        - This suggests that frequent attendance positively impacts academic performance.\n",
    "\n",
    "    - **Role of `Teacher_Quality`**\n",
    "\n",
    "        - The coefficient for `Teacher_Quality` (0.1246, p < 0.001) shows a positive and statistically significant relationship with exam scores.\n",
    "        - This implies that teacher quality contributes to better academic performance, but its impact is smaller compared to attendance.\n",
    "\n",
    "    - **Interaction Between `Attendance` and `Teacher_Quality`**\n",
    "\n",
    "        - The interaction term (`Interaction_TQ`: 0.0049, p = 0.770) is not statistically significant.\n",
    "        - This suggests that `Teacher_Quality` does not moderate the relationship between `Attendance` and Exam_Score.\n",
    "        - In other words, the effect of attendance on exam scores is almost independent of teacher quality.\n",
    "\n",
    "    - **Future Directions**\n",
    "\n",
    "        - While `Teacher_Quality` is not a significant moderator, the role of `Motivation_Level` needs further investigation to determine if it alters the relationship between attendance and exam scores.\n",
    "        - Additionally, other factors not included in the current model, such as the learning environment, family support, or curriculum content, may act as mediators or moderators.\n",
    "\n",
    "2. **Preliminary Conclusion**\n",
    "\n",
    "    - **Partial Answer to the Research Question:**\n",
    "\n",
    "        - `Teacher_Quality` is not a significant moderator in the relationship between `Attendance` and `Exam_Score`.\n",
    "        - Further analysis is required to explore the potential moderating role of `Motivation_Level`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **`Motivation_Level` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datadata\n",
    "data_std['Interaction_ML'] = data_std['Attendance'] * data_std['Motivation_Level']\n",
    "X = sm.add_constant(data_std[['Attendance', 'Motivation_Level', 'Interaction_ML']])\n",
    "y = data_std['Exam_Score']\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "1. **Results of the Analysis for \"`Motivation_Level`\":**\n",
    "    - **Relationship between `Attendance` and `Exam_Score`:** \n",
    "        - Similar to `Teacher_Quality`, `Attendance` has a strong impact on `Exam_Score` with a coefficient (coef) of 0.5904 and a p-value < 0.05. This suggests that class attendance positively influences exam scores.\n",
    "\n",
    "    - **Relationship between `Motivation_Level` and `Exam_Score`:** \n",
    "        - `Motivation_Level` also significantly affects the exam score, with a coefficient of 0.1323 and a p-value < 0.05. This indicates that different levels of motivation may influence exam performance.\n",
    "\n",
    "    - **Interaction between `Attendance` and `Motivation_Level`:**\n",
    "        - The interaction term (`Interaction_ML`) has a coefficient of -0.0094 and a p-value of 0.516 (greater than 0.05), suggesting that there is no significant moderation effect from the interaction between attendance and motivation level. This reinforces the conclusion that motivation level does not significantly affect the relationship between attendance and exam scores.\n",
    "\n",
    "2. **Conclusion from the Model:**\n",
    "    - The relationship between Attendance and Exam_Score is not moderated by `Motivation_Level` (similar to `Teacher_Quality`), as the interaction term is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Evaluate Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *4.1 Visualize interactive effects*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Direct effect of `Attendance` vs `Exam_Score*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Attendance vs Exam_Score with trend line\n",
    "sns.scatterplot(\n",
    "    data=data_std, x='Attendance', y='Exam_Score',  alpha=0.6, color='blue'\n",
    ")\n",
    "sns.regplot(\n",
    "    data=data_std, x='Attendance', y='Exam_Score',  scatter=False, color='red'\n",
    ")\n",
    "plt.title('Direct Effect: Attendance vs Exam_Score')\n",
    "plt.xlabel('Attendance')\n",
    "plt.ylabel('Exam Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. **`Teacher_Quality` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Attendance vs Exam_Score by Teacher_Quality levels\n",
    "sns.lmplot(\n",
    "    data=data_std,\n",
    "    x='Attendance',\n",
    "    y='Exam_Score',\n",
    "    hue='Teacher_Quality',\n",
    "    palette='viridis',\n",
    "    height=6,\n",
    "    aspect=2,\n",
    "    scatter_kws={'alpha': 0.6},\n",
    "    line_kws={'linewidth': 2},\n",
    "    ci=None,\n",
    ")\n",
    "plt.title('Effect by Teacher Quality Levels')\n",
    "plt.legend()\n",
    "# Adjust layout for better visibility\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **`Motivation_Level` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Attendance vs Exam_Score by Motivation_Level levels\n",
    "sns.lmplot(\n",
    "    data=data_std,\n",
    "    x='Attendance',\n",
    "    y='Exam_Score',\n",
    "    hue='Motivation_Level',\n",
    "    palette='viridis',\n",
    "    height=6,\n",
    "    aspect=2,\n",
    "    scatter_kws={'alpha': 0.6},\n",
    "    line_kws={'linewidth': 2},\n",
    "    ci=None,\n",
    ")\n",
    "plt.title('Effect by Motivation_Level Levels')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout for better visibility\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. **Comment**\n",
    "- The visualizations support the conclusion that `Teacher_Quality` and `Motivation_Level` are not significant moderators in the relationship between `Attendance` and `Exam_Score`. \n",
    "- Changes in class attendance do not show significant differences depending on the levels of these factors. \n",
    "- Therefore, improving `Teacher_Quality` and `Motivation_Level` may improve exam scores, but it does not alter the fundamental relationship between `Attendance` and `Exam_Score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Interpret and Conclude**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Summary of Findings:**\n",
    "\n",
    "- **Attendance and Exam Score**: There is a strong, positive relationship between `Attendance` and `Exam_Score`, indicating that higher attendance is associated with better exam performance.\n",
    "  \n",
    "- **Teacher Quality**: While `Teacher_Quality` does have a significant direct effect on `Exam_Score`, the interaction between `Attendance` and `Teacher_Quality` is not significant. This suggests that `Teacher_Quality` does not moderate the relationship between attendance and exam scores, meaning the effect of attendance on exam scores is largely independent of the teacher's quality.\n",
    "\n",
    "- **Motivation Level**: Similarly, while `Motivation_Level` also significantly affects `Exam_Score`, the interaction term between `Attendance` and `Motivation_Level` is not significant. This suggests that motivation level does not significantly moderate the relationship between attendance and exam scores.\n",
    "\n",
    "##### **Actionable Insights:**\n",
    "\n",
    "1. **Teacher Quality**: Since `Teacher_Quality` does not moderate the relationship between `Attendance` and `Exam_Score`, improving teacher effectiveness may still be beneficial for enhancing overall exam performance, but it may not directly influence the impact of attendance on exam scores.\n",
    "\n",
    "2. **Motivation**: While motivation is significant in its own right, interventions targeting motivation may be more useful as standalone efforts rather than attempts to modify how attendance influences exam scores.\n",
    "\n",
    "3. **Focus on Attendance**: Since `Attendance` is the most significant predictor of `Exam_Score`, schools and educational institutions could focus on improving attendance through interventions, such as providing incentives for high attendance or addressing factors that contribute to poor attendance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
